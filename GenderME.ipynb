{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GenderME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What can the code currently do?\n",
    "1. [x] Find approximate beginning of speeches. \n",
    "2. [x] Split into text parts consisting of president speech portion and following speech.\n",
    "3. [ ] Create table of political affiliation, e.g. Alice Weidel - AfD etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do we still need to implement?\n",
    "1. [ ] Find *actual* beginning of speeches by politicians who are **not** (vice) president.\n",
    "2. [ ] Get rid of unnecessary text parts without speeches.\n",
    "3. [ ] Get rid of interjections.\n",
    "4. [ ] Find instances of gendered and ungendered speech in text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes on the .txt:** \n",
    "1. ~~Schäuble announces speakers. (Relevant for finding the beginning of new speeches?)~~ Actually, numerous (vice) presidents announce speakers, this needs to be taken into account. (Search for _präsident_ instead of Schäuble is the better approach).\n",
    "2. Interjections from other politicians marked with `(...)` -- in the interjections, party affiliation is marked with `[...]`.\n",
    "3. The begin of a speech is marked with ':' -- however, these also appear in speeches. For normal speakers, party affiliation is indicated with `(...)`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Needed packages:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'readr' successfully unpacked and MD5 sums checked\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\Arilila\\AppData\\Local\\Temp\\RtmpqMM0yG\\downloaded_packages\n",
      "package 'tidyverse' successfully unpacked and MD5 sums checked\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\Arilila\\AppData\\Local\\Temp\\RtmpqMM0yG\\downloaded_packages\n"
     ]
    }
   ],
   "source": [
    "options(warn=-1)               #hide warning messages; makes the code look nicer\n",
    "\n",
    "install.packages(\"readr\")\n",
    "install.packages(\"tidyverse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-- Attaching packages --------------------------------------- tidyverse 1.3.0 --\n",
      "v ggplot2 3.3.3     v dplyr   1.0.4\n",
      "v tibble  3.0.6     v stringr 1.4.0\n",
      "v tidyr   1.1.2     v forcats 0.5.1\n",
      "v purrr   0.3.4     \n",
      "-- Conflicts ------------------------------------------ tidyverse_conflicts() --\n",
      "x dplyr::filter() masks stats::filter()\n",
      "x dplyr::lag()    masks stats::lag()\n"
     ]
    }
   ],
   "source": [
    "library(\"readr\")\n",
    "library(\"tidyverse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load test file `plenartest.txt`.\n",
    "\n",
    "Because the original txt.file is not formatted, our analysis of the file needs to include many different aspects, e.g. finding a useful division into paragraphs ourselves. Therefore we need to split the whole document by spaces to look at the individual words and their interaction and relation with each other rather than the text as a whole. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "plenar_test <- read_file(\"res/plenartest.txt\")\n",
    "\n",
    "plenar_test <- str_replace_all(plenar_test, \"DIE LINKE\", \"DIE_LINKE\")\n",
    "plenar_test <- str_replace_all(plenar_test, \"BÜNDNIS 90/DIE GRÜNEN\", \"BÜNDNIS_90/DIE_GRÜNEN\")\n",
    "\n",
    "plenar_test_vec <- strsplit(plenar_test, \" \")[[1]];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~Find all instances of `Präsident Dr. Wolfgang Schäuble:` in the .txt file. This helps us:~~\n",
    "\n",
    "Find all instances of words containing `präsident` in the .txt file. Then, find the first occurance of a capitalised token followed by a colon. (Which  should be the last name of the president -- to assure this, the distance between the word containing `präsident` and the aforementioned token should not be more than the defined threshold.) \n",
    "\n",
    "This helps us:\n",
    "\n",
    "1. Find the beginning of the relevant text, allowing us to purge the meaningless beginning and end each of the plenary session txt files contains.\n",
    "2. Find the *approximate* beginning of the individual speeches, since presidents and vice presidents introduce all speakers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us illustrate this using an example from the test .txt file:\n",
    "\n",
    "[...] Der gesamte und damit endgültige Stenografische Bericht der 209. Sitzung wird am 16. Februar 2021 veröffentlicht. **Präsident** *Dr. Wolfgang* **Schäuble:** Guten Morgen, liebe Kolleginnen und Kollegen! [...]\n",
    "\n",
    "In this instance, the distance between the word **Präsident** and **his last name (plus colon)** is *2*. In the following code, we will use a distance of 4 as threshold to account for PhD title, first name and last name, as well as a placeholder for people with the first names et cetera.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_letter_is_upper <- function(text){\n",
    "    first_letter <- substring(text, 1, 1)\n",
    "    return(grepl(\"^[[:upper:]]+$\", first_letter))\n",
    "}\n",
    "\n",
    "last_letter <- function(text){\n",
    "    return(\n",
    "        substring(text, nchar(text))\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "len <- length(plenar_test_vec)\n",
    "\n",
    "president_spotted <- FALSE\n",
    "president_position <- -1\n",
    "president_positions_vec <- vector()\n",
    "\n",
    "for(i in 1:len) {\n",
    "    token <- plenar_test_vec[i]\n",
    "    token_lower <- tolower(token)\n",
    "    \n",
    "    if(grepl(\"präsident\", token_lower, fixed = TRUE)) {\n",
    "        president_spotted <- TRUE\n",
    "        president_position <- i\n",
    "    } \n",
    "    \n",
    "    president_dist <- i-president_position-1\n",
    "    \n",
    "    if(president_spotted && president_dist<=4){\n",
    "        \n",
    "        if(first_letter_is_upper(token) && last_letter(token)==':'){\n",
    "            president_positions_vec <- c(president_positions_vec, president_position)\n",
    "            president_spotted <- FALSE    \n",
    "        }\n",
    "    }\n",
    "    else{\n",
    "        president_spotted <- FALSE\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "173"
      ],
      "text/latex": [
       "173"
      ],
      "text/markdown": [
       "173"
      ],
      "text/plain": [
       "[1] 173"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "length(president_positions_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following this step, we split the text into segments which are prefaced by one of the (vice) presidents speaking. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_segments <- list()\n",
    "len2 <- length(president_positions_vec)\n",
    "\n",
    "for(i in 1:len2-1){\n",
    "    if(i == 0){\n",
    "        next\n",
    "    }\n",
    "    \n",
    "    first_president_pos <- president_positions_vec[i]\n",
    "    second_president_pos <- president_positions_vec[i+1]\n",
    "\n",
    "    president_tokens_vec <- plenar_test_vec[first_president_pos:second_president_pos]\n",
    "    president_tokens_vec <- president_tokens_vec[1:length(president_tokens_vec)-1]\n",
    "    \n",
    "    text_segments[[length(text_segments) + 1]]<- president_tokens_vec\n",
    "}\n",
    "\n",
    "last_president_pos <- president_positions_vec[length(president_positions_vec)]\n",
    "president_tokens_vec <- plenar_test_vec[last_president_pos:length(plenar_test_vec)]\n",
    "\n",
    "text_segments[[length(text_segments) + 1]]<- president_tokens_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Vizepräsident Wolfgang Kubicki: Vielen Dank, Herr Kollege Sauter. – Die nachfolgende Rednerin ist die Kollegin Heike Hänsel, Fraktion Die Linke. (Beifall bei der LINKEN) Heike Hänsel DIE_LINKE Heike Hänsel (DIE_LINKE): Herr Präsident! Sehr geehrte Kolleginnen und Kollegen! Die Bundesregierung will erneut den NATO-Militäreinsatz Sea Guardian im Mittelmeer verlängern, um angeblich Terrorismus zu bekämpfen und den Waffenschmuggel per Schiff, zum Beispiel nach Libyen, zu stoppen. Wir haben doch aber alle erst letztes Jahr erlebt, dass türkische Schiffe auf dem Weg nach Libyen kontrolliert werden sollten und wie kläglich die NATO dabei gescheitert ist. Ein französisches Schiff wurde sogar von einem Kriegsschiff des NATO-Partners Türkei bei dem Versuch der Kontrolle bedroht. Frankreich hatte sich daraufhin aus dieser NATO-Mission erst mal zurückgezogen. Da frage ich mich schon, wie Sie eigentlich dazu kommen, Herr Tauber, von „erfolgreich“ zu sprechen. Was ist denn an dieser Mission eigentlich erfolgreich? (Beifall bei der LINKEN) Diese und weitere Vorfälle im Zusammenhang mit Irini zeigen doch, dass dieser Einsatz eine einzige für die Steuerzahlerinnen und Steuerzahler kostspielige Farce ist. Auch die Entgrenzung des Mandats, thematisch und räumlich, der gesamte Mittelmeerraum plus Zugänge plus Luftraum, ist völlig inakzeptabel und trägt nur zur weiteren Militarisierung der gesamten Mittelmeerregion bei. Wir werden gegen die Verlängerung dieses Mandats stimmen. (Beifall bei der LINKEN) Wenn die Bundesregierung jetzt wirklich etwas gegen die Bewaffnung der Konfliktparteien in Libyen tun will, dann würde sie sofort keine Waffen mehr an die Länder liefern, die die Konfliktparteien in Libyen militärisch unterstützen, wie zum Beispiel Ägypten, die Vereinigten Arabischen Emirate und allen voran die Türkei. Aber wir wissen ja: Das Gegenteil ist leider der Fall. Meine Fraktion fordert seit Langem, dass die Bundesregierung sofort ein Verbot von Rüstungsexporten erlässt, (Beifall bei der LINKEN) auch um den Konflikt in Libyen nicht weiter zu nähren; denn wir sind ja auch trotz begrüßenswerter politischer Vereinbarungen von einem Frieden weit entfernt. Der Vorfall zeigt aber auch mit aller Deutlichkeit, dass Sea Guardian die selbsterklärten Vorgaben eben nicht erfüllt. Vielmehr trägt auch dieser Einsatz in Zusammenarbeit mit dem anderen Militäreinsatz EUNAVFOR MED Irini zur militärischen Flüchtlingsabwehr bei und macht das Mittelmeer immer mehr zum undurchdringlichen Bollwerk der Abschottung. Dies ist angesichts von offiziell mehr als 20 000 Toten – die Dunkelziffer ist weit höher –, also Menschen, die seit 2014 im Mittelmeer ertrunken sind, nur zynisch und hat mit der viel zitierten europäischen Idee nichts zu tun. (Beifall bei der LINKEN) Übrigens hat es auch mit europäischen Werten nichts zu tun, dass immer noch viele Menschen als Geflüchtete auf den griechischen Inseln bei dieser Eiseskälte festsitzen und immer noch nicht hierherkommen konnten – das ist eine Schande! –, obwohl wir so oft darüber diskutiert haben. (Beifall bei der LINKEN) Statt einer Militärmission zur Abschottung gegen Flüchtlinge brauchen wir endlich eine staatliche zivile Seenotrettung im Mittelmeer, und die freiwilligen Seenotretterinnen und Seenotretter dürfen nicht länger kriminalisiert werden. Das ist nämlich eine Schande, dass sie auch noch daran gehindert werden, Menschen zu retten. (Beifall bei der LINKEN) Wir sagen: Zivile Seenotrettung statt Sea Guardian! Das ist die richtige Antwort in dieser Zeit. (Beifall bei der LINKEN)\"\n"
     ]
    }
   ],
   "source": [
    "print(paste(text_segments[[106]], collapse = ' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we try to find the *actual* beginning of the speeches by definining a vector with likely buzzwords, such as party affiliation (e.g. SPD) or political office (e.g. Bundeskanzlerin)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARTIES <- c(\"CDU/CSU\", \"DIE_LINKE\", \"SPD\", \"FDP\", \"AfD\", \"BÜNDNIS_90/DIE_GRÜNEN\")\n",
    "\n",
    "get_party <- function(token){\n",
    "    for(party in PARTIES){\n",
    "        if(token == paste(\"(\", party, \"):\", sep='')){\n",
    "            return(party)\n",
    "        }\n",
    "    }\n",
    "    return(\"\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_speaker <- function(text_segment_vec, start_pos, found_party){\n",
    "    speaker_name_start <- start_pos\n",
    "    \n",
    "    while(speaker_name_start > start_pos - 10){\n",
    "        if(text_segment_vec[speaker_name_start] == found_party){\n",
    "            speaker = text_segment_vec[(speaker_name_start+1):start_pos]\n",
    "            return(\n",
    "                paste(speaker, collapse = ' ')\n",
    "            )\n",
    "        }\n",
    "        \n",
    "        speaker_name_start <- speaker_name_start - 1\n",
    "    }\n",
    "    \n",
    "    return(\"No Name Found\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_party_for_segment <- function(text_segment_vec){\n",
    "    for(i in 1:length(text_segment_vec)){\n",
    "        token <- text_segment_vec[i]\n",
    "        found_party <- get_party(token)\n",
    "        if(found_party != \"\"){\n",
    "            speaker <- get_speaker(text_segment_vec, i-1, found_party)\n",
    "            return(\n",
    "                list(party=found_party, pos=i, speaker=speaker)\n",
    "            )\n",
    "        }\n",
    "        \n",
    "    }\n",
    "    return(\n",
    "        list(party=\"-\", pos=-1, name=\"\")\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$party\n",
      "[1] \"BÜNDNIS_90/DIE_GRÜNEN\"\n",
      "\n",
      "$pos\n",
      "[1] 33\n",
      "\n",
      "$speaker\n",
      "[1] \"Omid Nouripour\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "len3 <- length(text_segments)\n",
    "\n",
    "for(i in 107:len3) {  \n",
    "    result <- get_party_for_segment(text_segments[[i]])\n",
    "    print(result)\n",
    "    break\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract interjections `(...)`. \n",
    "\n",
    "After this step, we have our variable `plenar_test` without interjections and a second variable named `interjections` with only the interjections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parenthesis_pattern <- \"(?=\\\\().*?(?<=\\\\))(?:[^-a-z0-9A-Z_]|$)\"\n",
    "\n",
    "interjections <- regmatches(\n",
    "    plenar_test, \n",
    "    gregexpr(parenthesis_pattern, plenar_test, perl=T),\n",
    "    invert = FALSE\n",
    ")[[1]]\n",
    "\n",
    "plenar_test <- regmatches(\n",
    "    plenar_test, \n",
    "    gregexpr(parenthesis_pattern, plenar_test, perl=T), \n",
    "    invert = TRUE\n",
    ")[[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command filters the interjections. The output are interjections with dialogue elements. (This might be useful for later analysis.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for(interjection in interjections){\n",
    "#     if(grepl(':', interjection, fixed = TRUE)){\n",
    "#         print(interjection)\n",
    "#     } \n",
    "# }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
