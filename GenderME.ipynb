{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GenderME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What can the code currently do?\n",
    "1. Find approximate beginning of speeches. \n",
    "2. \n",
    "3. \n",
    "...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do we still need to implement?\n",
    "1. Split into text parts consisting of president speech portion and following speech.\n",
    "2. Find *actual* beginning of speeches by politicians who are **not** (vice) president.\n",
    "3. Create table of political affiliation, e.g. Alice Weidel - AfD etc.\n",
    "4. Get rid of unnecessary text parts without speeches.\n",
    "5. Get rid of interjections.\n",
    "6. Find instances of gendered and ungendered speech in text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes on the .txt:** \n",
    "1. ~~Schäuble announces speakers. (Relevant for finding the beginning of new speeches?)~~ Actually, numerous (vice) presidents announce speakers, this needs to be taken into account. (Search for _präsident_ instead of Schäuble is the better approach).\n",
    "2. Interjections from other politicians marked with `(...)` -- in the interjections, party affiliation is marked with `[...]`.\n",
    "3. The begin of a speech is marked with ':' -- however, these also appear in speeches. For normal speakers, party affiliation is indicated with `(...)`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Needed packages:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'readr' successfully unpacked and MD5 sums checked\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\Arilila\\AppData\\Local\\Temp\\RtmpOAwDkp\\downloaded_packages\n",
      "package 'tidyverse' successfully unpacked and MD5 sums checked\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\Arilila\\AppData\\Local\\Temp\\RtmpOAwDkp\\downloaded_packages\n"
     ]
    }
   ],
   "source": [
    "options(warn=-1)               #hide warning messages; makes the code look nicer\n",
    "\n",
    "install.packages(\"readr\")\n",
    "install.packages(\"tidyverse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-- Attaching packages --------------------------------------- tidyverse 1.3.0 --\n",
      "v ggplot2 3.3.3     v dplyr   1.0.4\n",
      "v tibble  3.0.6     v stringr 1.4.0\n",
      "v tidyr   1.1.2     v forcats 0.5.1\n",
      "v purrr   0.3.4     \n",
      "-- Conflicts ------------------------------------------ tidyverse_conflicts() --\n",
      "x dplyr::filter() masks stats::filter()\n",
      "x dplyr::lag()    masks stats::lag()\n"
     ]
    }
   ],
   "source": [
    "library(\"readr\")\n",
    "library(\"tidyverse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load test file `plenartest.txt`.\n",
    "\n",
    "Because the original txt.file is not formatted, our analysis of the file needs to include many different aspects, e.g. finding a useful division into paragraphs ourselves. Therefore we need to split the whole document by spaces to look at the individual words and their interaction and relation with each other rather than the text as a whole. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plenar_test <- read_file(\"res/plenartest.txt\")\n",
    "plenar_test_vec <- strsplit(plenar_test, \" \")[[1]];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~Find all instances of `Präsident Dr. Wolfgang Schäuble:` in the .txt file. This helps us:~~\n",
    "\n",
    "Find all instances of words containing `präsident` in the .txt file. Then, find the first occurance of a capitalised token followed by a colon. (Which  should be the last name of the president -- to assure this, the distance between the word containing `präsident` and the aforementioned token should not be more than the defined threshold.) \n",
    "\n",
    "This helps us:\n",
    "\n",
    "1. Find the beginning of the relevant text, allowing us to purge the meaningless beginning and end each of the plenary session txt files contains.\n",
    "2. Find the *approximate* beginning of the individual speeches, since presidents and vice presidents introduce all speakers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us illustrate this using an example from the test .txt file:\n",
    "\n",
    "[...] Der gesamte und damit endgültige Stenografische Bericht der 209. Sitzung wird am 16. Februar 2021 veröffentlicht. **Präsident** *Dr. Wolfgang* **Schäuble:** Guten Morgen, liebe Kolleginnen und Kollegen! [...]\n",
    "\n",
    "In this instance, the distance between the word **Präsident** and **his last name (plus colon)** is *2*. In the following code, we will use a distance of 4 as threshold to account for PhD title, first name and last name, as well as a placeholder for people with the first names et cetera.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_letter_is_upper <- function(text){\n",
    "    first_letter <- substring(text, 1, 1)\n",
    "    return(grepl(\"^[[:upper:]]+$\", first_letter))\n",
    "}\n",
    "\n",
    "last_letter <- function(text){\n",
    "    return(\n",
    "        substring(text, nchar(text))\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "len <- length(plenar_test_vec)\n",
    "\n",
    "president_spotted <- FALSE\n",
    "president_position <- -1\n",
    "president_positions_list <- list() \n",
    "\n",
    "for(i in 1:len) {\n",
    "    token <- plenar_test_vec[i]\n",
    "    token_lower <- tolower(token)\n",
    "    \n",
    "    if(grepl(\"präsident\", token_lower, fixed = TRUE)) {\n",
    "        president_spotted <- TRUE\n",
    "        president_position <- i\n",
    "    } \n",
    "    \n",
    "    president_dist <- i-president_position-1\n",
    "    \n",
    "    if(president_spotted && president_dist<=4){\n",
    "        \n",
    "        if(first_letter_is_upper(token) && last_letter(token)==':'){\n",
    "        president_positions_list <- c(president_positions_list, president_position)\n",
    "        president_spotted <- FALSE    \n",
    "        }\n",
    "    }\n",
    "    else{\n",
    "        president_spotted <- FALSE\n",
    "    }\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following this step, we split the text into segments which are prefaced by one of the (vice) presidents speaking. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      "[1] 2965\n",
      "\n",
      "[[1]]\n",
      "[1] 6349\n",
      "\n",
      "[[1]]\n",
      "[1] 7364\n",
      "\n",
      "[[1]]\n",
      "[1] 8556\n",
      "\n",
      "[[1]]\n",
      "[1] 10151\n",
      "\n",
      "[[1]]\n",
      "[1] 12154\n",
      "\n",
      "[[1]]\n",
      "[1] 13625\n",
      "\n",
      "[[1]]\n",
      "[1] 15252\n",
      "\n",
      "[[1]]\n",
      "[1] 16300\n",
      "\n",
      "[[1]]\n",
      "[1] 17158\n",
      "\n",
      "[[1]]\n",
      "[1] 17449\n",
      "\n",
      "[[1]]\n",
      "[1] 17468\n",
      "\n",
      "[[1]]\n",
      "[1] 18221\n",
      "\n",
      "[[1]]\n",
      "[1] 18998\n",
      "\n",
      "[[1]]\n",
      "[1] 19039\n",
      "\n",
      "[[1]]\n",
      "[1] 19228\n",
      "\n",
      "[[1]]\n",
      "[1] 19382\n",
      "\n",
      "[[1]]\n",
      "[1] 20125\n",
      "\n",
      "[[1]]\n",
      "[1] 20991\n",
      "\n",
      "[[1]]\n",
      "[1] 21313\n",
      "\n",
      "[[1]]\n",
      "[1] 21987\n",
      "\n",
      "[[1]]\n",
      "[1] 23202\n",
      "\n",
      "[[1]]\n",
      "[1] 24363\n",
      "\n",
      "[[1]]\n",
      "[1] 25158\n",
      "\n",
      "[[1]]\n",
      "[1] 26767\n",
      "\n",
      "[[1]]\n",
      "[1] 26824\n",
      "\n",
      "[[1]]\n",
      "[1] 27937\n",
      "\n",
      "[[1]]\n",
      "[1] 28742\n",
      "\n",
      "[[1]]\n",
      "[1] 28784\n",
      "\n",
      "[[1]]\n",
      "[1] 30086\n",
      "\n",
      "[[1]]\n",
      "[1] 30654\n",
      "\n",
      "[[1]]\n",
      "[1] 31202\n",
      "\n",
      "[[1]]\n",
      "[1] 31274\n",
      "\n",
      "[[1]]\n",
      "[1] 32074\n",
      "\n",
      "[[1]]\n",
      "[1] 33308\n",
      "\n",
      "[[1]]\n",
      "[1] 34199\n",
      "\n",
      "[[1]]\n",
      "[1] 34875\n",
      "\n",
      "[[1]]\n",
      "[1] 35645\n",
      "\n",
      "[[1]]\n",
      "[1] 36528\n",
      "\n",
      "[[1]]\n",
      "[1] 37045\n",
      "\n",
      "[[1]]\n",
      "[1] 38009\n",
      "\n",
      "[[1]]\n",
      "[1] 38536\n",
      "\n",
      "[[1]]\n",
      "[1] 39061\n",
      "\n",
      "[[1]]\n",
      "[1] 39650\n",
      "\n",
      "[[1]]\n",
      "[1] 40085\n",
      "\n",
      "[[1]]\n",
      "[1] 40343\n",
      "\n",
      "[[1]]\n",
      "[1] 40374\n",
      "\n",
      "[[1]]\n",
      "[1] 40466\n",
      "\n",
      "[[1]]\n",
      "[1] 40686\n",
      "\n",
      "[[1]]\n",
      "[1] 41326\n",
      "\n",
      "[[1]]\n",
      "[1] 41369\n",
      "\n",
      "[[1]]\n",
      "[1] 42098\n",
      "\n",
      "[[1]]\n",
      "[1] 42820\n",
      "\n",
      "[[1]]\n",
      "[1] 43344\n",
      "\n",
      "[[1]]\n",
      "[1] 43957\n",
      "\n",
      "[[1]]\n",
      "[1] 45214\n",
      "\n",
      "[[1]]\n",
      "[1] 46239\n",
      "\n",
      "[[1]]\n",
      "[1] 46520\n",
      "\n",
      "[[1]]\n",
      "[1] 46936\n",
      "\n",
      "[[1]]\n",
      "[1] 47553\n",
      "\n",
      "[[1]]\n",
      "[1] 47586\n",
      "\n",
      "[[1]]\n",
      "[1] 47660\n",
      "\n",
      "[[1]]\n",
      "[1] 48591\n",
      "\n",
      "[[1]]\n",
      "[1] 49243\n",
      "\n",
      "[[1]]\n",
      "[1] 49327\n",
      "\n",
      "[[1]]\n",
      "[1] 49386\n",
      "\n",
      "[[1]]\n",
      "[1] 50497\n",
      "\n",
      "[[1]]\n",
      "[1] 50989\n",
      "\n",
      "[[1]]\n",
      "[1] 51433\n",
      "\n",
      "[[1]]\n",
      "[1] 52323\n",
      "\n",
      "[[1]]\n",
      "[1] 53261\n",
      "\n",
      "[[1]]\n",
      "[1] 56400\n",
      "\n",
      "[[1]]\n",
      "[1] 57146\n",
      "\n",
      "[[1]]\n",
      "[1] 57788\n",
      "\n",
      "[[1]]\n",
      "[1] 58683\n",
      "\n",
      "[[1]]\n",
      "[1] 59419\n",
      "\n",
      "[[1]]\n",
      "[1] 60232\n",
      "\n",
      "[[1]]\n",
      "[1] 61043\n",
      "\n",
      "[[1]]\n",
      "[1] 61963\n",
      "\n",
      "[[1]]\n",
      "[1] 62550\n",
      "\n",
      "[[1]]\n",
      "[1] 63366\n",
      "\n",
      "[[1]]\n",
      "[1] 64277\n",
      "\n",
      "[[1]]\n",
      "[1] 64959\n",
      "\n",
      "[[1]]\n",
      "[1] 66071\n",
      "\n",
      "[[1]]\n",
      "[1] 66640\n",
      "\n",
      "[[1]]\n",
      "[1] 67264\n",
      "\n",
      "[[1]]\n",
      "[1] 67840\n",
      "\n",
      "[[1]]\n",
      "[1] 68377\n",
      "\n",
      "[[1]]\n",
      "[1] 68992\n",
      "\n",
      "[[1]]\n",
      "[1] 69391\n",
      "\n",
      "[[1]]\n",
      "[1] 70173\n",
      "\n",
      "[[1]]\n",
      "[1] 71281\n",
      "\n",
      "[[1]]\n",
      "[1] 71955\n",
      "\n",
      "[[1]]\n",
      "[1] 72446\n",
      "\n",
      "[[1]]\n",
      "[1] 72498\n",
      "\n",
      "[[1]]\n",
      "[1] 73120\n",
      "\n",
      "[[1]]\n",
      "[1] 73632\n",
      "\n",
      "[[1]]\n",
      "[1] 74160\n",
      "\n",
      "[[1]]\n",
      "[1] 74969\n",
      "\n",
      "[[1]]\n",
      "[1] 75522\n",
      "\n",
      "[[1]]\n",
      "[1] 75638\n",
      "\n",
      "[[1]]\n",
      "[1] 75697\n",
      "\n",
      "[[1]]\n",
      "[1] 76483\n",
      "\n",
      "[[1]]\n",
      "[1] 76979\n",
      "\n",
      "[[1]]\n",
      "[1] 77579\n",
      "\n",
      "[[1]]\n",
      "[1] 78060\n",
      "\n",
      "[[1]]\n",
      "[1] 78571\n",
      "\n",
      "[[1]]\n",
      "[1] 79236\n",
      "\n",
      "[[1]]\n",
      "[1] 79850\n",
      "\n",
      "[[1]]\n",
      "[1] 80309\n",
      "\n",
      "[[1]]\n",
      "[1] 80723\n",
      "\n",
      "[[1]]\n",
      "[1] 81437\n",
      "\n",
      "[[1]]\n",
      "[1] 82212\n",
      "\n",
      "[[1]]\n",
      "[1] 83062\n",
      "\n",
      "[[1]]\n",
      "[1] 83102\n",
      "\n",
      "[[1]]\n",
      "[1] 83623\n",
      "\n",
      "[[1]]\n",
      "[1] 84179\n",
      "\n",
      "[[1]]\n",
      "[1] 84767\n",
      "\n",
      "[[1]]\n",
      "[1] 84797\n",
      "\n",
      "[[1]]\n",
      "[1] 84847\n",
      "\n",
      "[[1]]\n",
      "[1] 85432\n",
      "\n",
      "[[1]]\n",
      "[1] 86079\n",
      "\n",
      "[[1]]\n",
      "[1] 86580\n",
      "\n",
      "[[1]]\n",
      "[1] 87010\n",
      "\n",
      "[[1]]\n",
      "[1] 87888\n",
      "\n",
      "[[1]]\n",
      "[1] 88882\n",
      "\n",
      "[[1]]\n",
      "[1] 89520\n",
      "\n",
      "[[1]]\n",
      "[1] 89844\n",
      "\n",
      "[[1]]\n",
      "[1] 89863\n",
      "\n",
      "[[1]]\n",
      "[1] 90907\n",
      "\n",
      "[[1]]\n",
      "[1] 91177\n",
      "\n",
      "[[1]]\n",
      "[1] 91720\n",
      "\n",
      "[[1]]\n",
      "[1] 92000\n",
      "\n",
      "[[1]]\n",
      "[1] 92298\n",
      "\n",
      "[[1]]\n",
      "[1] 92739\n",
      "\n",
      "[[1]]\n",
      "[1] 93054\n",
      "\n",
      "[[1]]\n",
      "[1] 93796\n",
      "\n",
      "[[1]]\n",
      "[1] 94381\n",
      "\n",
      "[[1]]\n",
      "[1] 94996\n",
      "\n",
      "[[1]]\n",
      "[1] 95490\n",
      "\n",
      "[[1]]\n",
      "[1] 95876\n",
      "\n",
      "[[1]]\n",
      "[1] 96347\n",
      "\n",
      "[[1]]\n",
      "[1] 96963\n",
      "\n",
      "[[1]]\n",
      "[1] 97446\n",
      "\n",
      "[[1]]\n",
      "[1] 97925\n",
      "\n",
      "[[1]]\n",
      "[1] 98857\n",
      "\n",
      "[[1]]\n",
      "[1] 99800\n",
      "\n",
      "[[1]]\n",
      "[1] 100515\n",
      "\n",
      "[[1]]\n",
      "[1] 101352\n",
      "\n",
      "[[1]]\n",
      "[1] 101789\n",
      "\n",
      "[[1]]\n",
      "[1] 102250\n",
      "\n",
      "[[1]]\n",
      "[1] 102829\n",
      "\n",
      "[[1]]\n",
      "[1] 102880\n",
      "\n",
      "[[1]]\n",
      "[1] 103552\n",
      "\n",
      "[[1]]\n",
      "[1] 104420\n",
      "\n",
      "[[1]]\n",
      "[1] 105046\n",
      "\n",
      "[[1]]\n",
      "[1] 105995\n",
      "\n",
      "[[1]]\n",
      "[1] 106102\n",
      "\n",
      "[[1]]\n",
      "[1] 106592\n",
      "\n",
      "[[1]]\n",
      "[1] 107055\n",
      "\n",
      "[[1]]\n",
      "[1] 107525\n",
      "\n",
      "[[1]]\n",
      "[1] 108130\n",
      "\n",
      "[[1]]\n",
      "[1] 109404\n",
      "\n",
      "[[1]]\n",
      "[1] 109886\n",
      "\n",
      "[[1]]\n",
      "[1] 109945\n",
      "\n",
      "[[1]]\n",
      "[1] 110653\n",
      "\n",
      "[[1]]\n",
      "[1] 111119\n",
      "\n",
      "[[1]]\n",
      "[1] 111636\n",
      "\n",
      "[[1]]\n",
      "[1] 112370\n",
      "\n",
      "[[1]]\n",
      "[1] 112427\n",
      "\n",
      "[[1]]\n",
      "[1] 113116\n",
      "\n",
      "[[1]]\n",
      "[1] 113609\n",
      "\n",
      "[[1]]\n",
      "[1] 113683\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_segments <- list()\n",
    "len2 <- length(president_positions_list)\n",
    "for(i in 1:len2-1){\n",
    "    first_president_pos <- president_positions_list[i]\n",
    "    second_president_pos <- president_positions_list[i+1]\n",
    "    #TODO NEW VEC/LIST\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we try to find the *actual* beginning of the speeches by definining a vector with likely buzzwords, such as party affiliation (e.g. SPD) or political office (e.g. Bundeskanzlerin)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract interjections `(...)`. \n",
    "\n",
    "After this step, we have our variable `plenar_test` without interjections and a second variable named `interjections` with only the interjections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parenthesis_pattern <- \"(?=\\\\().*?(?<=\\\\))(?:[^-a-z0-9A-Z_]|$)\"\n",
    "\n",
    "interjections <- regmatches(\n",
    "    plenar_test, \n",
    "    gregexpr(parenthesis_pattern, plenar_test, perl=T),\n",
    "    invert = FALSE\n",
    ")[[1]]\n",
    "\n",
    "plenar_test <- regmatches(\n",
    "    plenar_test, \n",
    "    gregexpr(parenthesis_pattern, plenar_test, perl=T), \n",
    "    invert = TRUE\n",
    ")[[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plenar_test <- paste(plenar_test, collapse = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command filters the interjections. The output are interjections with dialogue elements. (This might be useful for later analysis.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for(interjection in interjections){\n",
    "#     if(grepl(':', interjection, fixed = TRUE)){\n",
    "#         print(interjection)\n",
    "#     } \n",
    "# }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
